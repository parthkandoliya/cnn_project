{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w4h7Fb8OAye"
   },
   "source": [
    "# ðŸ“Š Data Analysis Report for Rice Leaf Disease Dataset\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ðŸ“‚ Dataset Overview\n",
    "\n",
    "The dataset consists of **119 images** of rice leaves categorized into three classes:\n",
    "\n",
    "- **Bacterial Leaf Blight**: 40 images  \n",
    "- **Brown Spot**: 40 images  \n",
    "- **Leaf Smut**: 39 images  \n",
    "\n",
    "These images are collected from infected rice plants, each showing distinct symptoms. The objective is to classify these images into the correct disease categories.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ðŸ§¾ Dataset Characteristics\n",
    "\n",
    "- **Small dataset size**: Only 119 images, which is limited for deep learning.  \n",
    "- **Class distribution**: Nearly balanced (around 40 images per class).  \n",
    "- **Image quality**: Varies in lighting, background, and leaf orientation.  \n",
    "- **Image format**: RGB images with 3 color channels (important for disease spot detection).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. âš ï¸ Challenges with the Dataset\n",
    "\n",
    "- **Limited sample size** â†’ Higher risk of overfitting.  \n",
    "- **Variability** â†’ Differences in angles, lighting, and background make learning harder.  \n",
    "- **Visual similarity** â†’ Some diseases look quite similar, leading to possible misclassification.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ðŸ› ï¸ Data Preprocessing & Cleaning\n",
    "\n",
    "- **Resizing** â†’ All images resized to a uniform size (e.g., 255x255 pixels).  \n",
    "- **Normalization** â†’ Pixel values scaled between 0 and 1.  \n",
    "- **Shuffling and batching** â†’ Applied for better training and to avoid bias.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. ðŸ” Data Augmentation\n",
    "\n",
    "To improve model performance and reduce overfitting, augmentation techniques were used:\n",
    "\n",
    "- Random **horizontal/vertical flips**  \n",
    "- Random **rotations**  \n",
    "- These simulate real-world variations and help the model generalize better.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. ðŸ”Ž Exploratory Data Analysis (EDA)\n",
    "\n",
    "- **Class count visualization** â†’ Checked if data is balanced.  \n",
    "- **Sample visualization** â†’ Displayed images from each class to understand appearance.  \n",
    "- **Label verification** â†’ Ensured correct labeling of images.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. âœ… Summary & Insights\n",
    "\n",
    "- Dataset is small but usable for training with augmentation and preprocessing.  \n",
    "- Data augmentation is **necessary** to improve learning and generalization.  \n",
    "- Preprocessing brings uniformity to image inputs.  \n",
    "- **Deep models or transfer learning** may be required due to visual similarity between disease classes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrNn8zvUOMK3"
   },
   "source": [
    "## Importing Libraries and Mount drive to Import Images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYOqZsth78AT",
    "outputId": "edce2866-b9f2-42ca-f538-6037e38a48e4"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import models,layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNtqaPla7T_U",
    "outputId": "691f693c-e2fc-4121-deda-6fbed7415583"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m CHANNEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      5\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      7\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     10\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/PRCP-1001-RiceLeaf/Data\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# or your actual path here\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE\n\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# set all the constants(hyperparameters)\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 255\n",
    "CHANNEL = 3\n",
    "EPOCHS = 20\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory='/content/drive/MyDrive/PRCP-1001-RiceLeaf/Data',  # or your actual path here\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_jDmpO39EIY",
    "outputId": "e97d0098-330f-4b7d-8cb8-412712b615c6"
   },
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4sTOwjb9EVR"
   },
   "source": [
    "## Label :-\n",
    "#### This part shows the labels corresponding to the images in the batch. It's a 1D tensor with a shape of (32), indicating the label for each image in the batch. The labels seem to be integers, ranging from 0 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDF3PFhR-R8k",
    "outputId": "fb023fe0-bbc4-46d8-ae89-0f2ba50dc5c2"
   },
   "outputs": [],
   "source": [
    "for image_batch,label_batch in dataset.take(1):\n",
    "    print(\"Image Batch Shape : \", image_batch.shape)\n",
    "    print(\"Single Image : \", image_batch[0])\n",
    "    print(\"Label Image numpy : \", label_batch.numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97APQGob9EX2",
    "outputId": "8c6c6d8a-fac8-46a7-c79b-d84e68a2167e"
   },
   "outputs": [],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Xr4cVjd_KlN"
   },
   "source": [
    "# EDA :-\n",
    "## Visualize some of the images from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "2rWcxfSm9Ea4",
    "outputId": "7ef335d9-95ee-4cfd-e629-3853c26c8f5b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for image_batch, labels_batch in dataset.take(1):\n",
    "    # Code to process the first batch of images and labels\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels_batch[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NBOz1V__r_F"
   },
   "source": [
    "## Function to Split Dataset\n",
    "### Dataset should be bifurcated into 3 subsets, namely:\n",
    "\n",
    "##### Training: Dataset to be used while training\n",
    "##### Validation: Dataset to be tested against while training\n",
    "##### Test: Dataset to be tested against after we trained a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ws16aTjc9EhB",
    "outputId": "b529b979-25e8-4d48-9a25-2f19f482fdbf"
   },
   "outputs": [],
   "source": [
    "total_batches = len(dataset)\n",
    "\n",
    "train_size = max(1, int(0.7 * total_batches))\n",
    "val_size = max(1, int(0.2 * total_batches))\n",
    "test_size = total_batches - train_size - val_size\n",
    "\n",
    "# Adjust again if needed\n",
    "if test_size <= 0:\n",
    "    test_size = 1\n",
    "    train_size = total_batches - val_size - test_size\n",
    "\n",
    "# Split dataset\n",
    "train_ds = dataset.take(train_size)\n",
    "val_ds = dataset.skip(train_size).take(val_size)\n",
    "test_ds = dataset.skip(train_size + val_size)\n",
    "\n",
    "# Print sizes\n",
    "print(f\"Train batches: {len(train_ds)}\")\n",
    "print(f\"Validation batches: {len(val_ds)}\")\n",
    "print(f\"Test batches: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDRDzSZD_5Vu"
   },
   "source": [
    "##Building the Model\n",
    "#### Creating a Layer for Resizing and Normalization Before we feed our images to network, we should be resizing it to the desired size. Moreover, to improve model performance, we should normalize the image pixel value (keeping them in range 0 and 1 by dividing by 256). This should happen while training as well as inference. Hence we can add that as a layer in our Sequential Model.\n",
    "\n",
    "#### You might be thinking why do we need to resize (256,256) image to again (256,256). You are right we don't need to but this will be useful when we are done with the training and start using the model for predictions. At that time somone can supply an image that is not (256,256) and this layer will resize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVg5BWmy_wyd"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dR7xNEY4_w1i"
   },
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.Resizing(IMAGE_SIZE, IMAGE_SIZE), # Changed from layers.preprocessing.Resizing\n",
    "  layers.Rescaling(1./255), # Changed from layers.preprocessing.Rescaling\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu2akdxDADAh"
   },
   "source": [
    "# ðŸ“Š Data Augmentation Report\n",
    "\n",
    "## ðŸ“ Why Data Augmentation Was Used\n",
    "\n",
    "In this project, the dataset consists of only **119 total images** across **three classes**:\n",
    "\n",
    "- 40 images of **Bacterial Leaf Blight**\n",
    "- 40 images of **Brown Spot**\n",
    "- 39 images of **Leaf Smut**\n",
    "\n",
    "This is a very small dataset for training a deep learning model. If trained without augmentation, the model would likely:\n",
    "\n",
    "- Overfit to the small training set\n",
    "- Fail to generalize on new or unseen images\n",
    "- Show poor validation and test accuracy\n",
    "\n",
    "To overcome this, **data augmentation** was applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EpjwJyk_w4L"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UfBNjfgAKjI"
   },
   "source": [
    "# Applying Data Augmentation to Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5ML6EM1_w7R",
    "outputId": "b09c64a3-4066-45cd-c2f9-7d2169f03ca7"
   },
   "outputs": [],
   "source": [
    "for batch in val_ds.take(1):\n",
    "    print(\"Validation batch found.\")\n",
    "\n",
    "for images, labels in val_ds.take(1):\n",
    "    print(f\"Validation batch shape: {images.shape}\")\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y)\n",
    ").prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5HJIMiT_w-K",
    "outputId": "bcda7c60-8280-419c-8b78-0827f9bbb8fa"
   },
   "outputs": [],
   "source": [
    "print(f\"Train batches: {len(train_ds)}\")\n",
    "print(f\"Validation batches: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjrU_QKDAWC3"
   },
   "source": [
    "# Model Architecture\n",
    "\n",
    "#### We use a CNN coupled with a Softmax activation in the output layer. We also add the initial layers for resizing, normalization and Data Augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6IREKkU_xBQ",
    "outputId": "7612b8af-0159-413f-ee8a-d871e00a4ce5"
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNEL)),\n",
    "    resize_and_rescale,\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0ICLQhS_xEH",
    "outputId": "233a1ee8-471c-4d09-9c93-e2d88616a45c"
   },
   "outputs": [],
   "source": [
    "print(f\"Length of train_ds: {len(train_ds)}\")\n",
    "print(f\"Length of val_ds: {len(val_ds)}\")\n",
    "print(f\"Length of test_ds: {len(test_ds)}\")\n",
    "\n",
    "if len(val_ds) == 0:\n",
    "    print(\"Warning: val_ds is empty. Validation metrics will not be available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "eUMrz0kG_xHG",
    "outputId": "cda2b17e-2172-4d10-fc7f-6f9d782658cb"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzNx63yOAqLg"
   },
   "source": [
    "## Compiling the Model\n",
    "We use adam Optimizer, SparseCategoricalCrossentropy for losses, accuracy as a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CG_Gs9PC_xKI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "optimizer = Nadam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',  # Use this if your labels are integers\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5CfpBwm_xNA",
    "outputId": "1e9f1d04-6f40-4c39-a42d-9daa90ed9645",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,  # Ensure val_ds is not None\n",
    "    epochs=85,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kD0bLUvC_xQJ",
    "outputId": "39274149-4262-4c06-8769-080218726ea6"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Hhr8DGS_xSz",
    "outputId": "c58b154d-23ee-4900-fec2-a1388910dbdf"
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmndkeTGBES4"
   },
   "source": [
    "## Plotting the Accuracy and Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3og22O8_xWH",
    "outputId": "d5363397-89ef-427b-84ce-428470fbff7e"
   },
   "outputs": [],
   "source": [
    "print(history)\n",
    "print(history.params)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAARcsqp_xYj",
    "outputId": "e2e8cdf5-d43b-4eca-a6f5-4cfcf8507223"
   },
   "outputs": [],
   "source": [
    "print(\"Available history keys:\", history.history.keys())\n",
    "if len(val_ds) == 0:\n",
    "    print(\"âš ï¸ Warning: Validation dataset is empty. No validation accuracy/loss will be recorded.\")\n",
    "history.history['loss'][:5] # show loss for first 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uE0TC3I7_xbJ"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "jm8nUlBT_xd7",
    "outputId": "cfefac2c-3b09-4bfc-9d40-dfbbf9e615f3"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history.get('val_accuracy')  # use .get() in case it's None\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss')\n",
    "\n",
    "epochs_range = range(len(acc))  # will automatically match the number of trained epochs\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "if val_acc:\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "if val_loss:\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYAmva17BT3y"
   },
   "source": [
    "# Run prediction on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T03orlk5_xgj",
    "outputId": "183812ab-fea2-4bf1-a7fc-1bc4da4ef9fd"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "aJMJMapz_xjw",
    "outputId": "ca960b4e-9144-4906-b078-21d2de7c0fee"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for images_batch, labels_batch in test_ds.take(1):\n",
    "\n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "\n",
    "    print(\"first image to predict\")\n",
    "    plt.imshow(first_image)\n",
    "    print(\"actual label:\",class_names[first_label])\n",
    "\n",
    "    batch_prediction = model.predict(images_batch)\n",
    "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6C0Nb5KBjA9"
   },
   "source": [
    "# ðŸ§  Inference Report\n",
    "\n",
    "## ðŸ“ Why Inference Was Used\n",
    "\n",
    "After training the model on a small dataset, inference was done to check how well the model predicts new, unseen images.\n",
    "\n",
    "## ðŸ” What Inference Does\n",
    "\n",
    "- Predicts classes for new images using the trained model  \n",
    "- Provides confidence scores for each prediction  \n",
    "- Helps verify model accuracy on test data\n",
    "\n",
    "## âœ… Benefits of Inference\n",
    "\n",
    "- Confirms modelâ€™s real-world performance  \n",
    "- Shows actual vs predicted results  \n",
    "- Measures prediction confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEdD7rKJBnvh"
   },
   "source": [
    "## Function for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zn2g9SVm_xnJ"
   },
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "O1-blYliBeLu",
    "outputId": "43afa1d5-6096-4cb4-9c8e-d9737dbddd04"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "\n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        actual_class = class_names[labels[i]]\n",
    "\n",
    "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FnvY23hBeOt",
    "outputId": "d2d17088-912b-4185-ec3e-df4843941acd"
   },
   "outputs": [],
   "source": [
    "model.save(\"Plant_leaf_diseases_detection_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zC550_WQBeU6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-Wy24or9EpV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uG1ItKiT9Es_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to Colab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
